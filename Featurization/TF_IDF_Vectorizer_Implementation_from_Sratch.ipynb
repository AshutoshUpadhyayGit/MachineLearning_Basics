{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnV82tg1xLi0"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bUsYm9wjxLi1"
      },
      "outputs": [],
      "source": [
        "## SkLearn# Collection of string documents\n",
        "\n",
        "corpus = [\n",
        "     'this is the first document',\n",
        "     'this document is the second document',\n",
        "     'and this is the third one',\n",
        "     'is this the first document',\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLwmFZfKxLi4"
      },
      "source": [
        "### SkLearn Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Np4dfQOkxLi4"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(corpus)\n",
        "skl_output = vectorizer.transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7Om8YpYxLi6",
        "outputId": "7be42a49-b182-4d67-b539-8128e26035e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n"
          ]
        }
      ],
      "source": [
        "# sklearn feature names, they are sorted in alphabetic order by default.\n",
        "\n",
        "print(vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTKplK96xLi-",
        "outputId": "dfa823da-ae4e-482c-9d4a-5856197b76f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
            " 1.         1.91629073 1.        ]\n"
          ]
        }
      ],
      "source": [
        "# Here we will print the sklearn tfidf vectorizer idf values after applying the fit method\n",
        "# After using the fit function on the corpus the vocab has 9 words in it, and each has its idf value.\n",
        "\n",
        "print(vectorizer.idf_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CTiWHygxLjA",
        "outputId": "d3f85c34-7eaf-4798-bacc-77ca8298cdbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shape of sklearn tfidf vectorizer output after applying transform method.\n",
        "\n",
        "skl_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDKEpbA-xLjD",
        "outputId": "83cbc83d-ec51-4d64-a80c-afd65bf27ecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 8)\t0.38408524091481483\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 1)\t0.46979138557992045\n"
          ]
        }
      ],
      "source": [
        "# sklearn tfidf values for first line of the above corpus.\n",
        "# Here the output is a sparse matrix\n",
        "\n",
        "print(skl_output[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QWo34hexLjF",
        "outputId": "6c7d73aa-1b63-449b-a927-e496bf2f9612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n"
          ]
        }
      ],
      "source": [
        "# sklearn tfidf values for first line of the above corpus.\n",
        "# To understand the output better, here we are converting the sparse output matrix to dense matrix and printing it.\n",
        "# Notice that this output is normalized using L2 normalization. sklearn does this by default.\n",
        "\n",
        "print(skl_output[0].toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfIwx5LzxLjI"
      },
      "source": [
        "### Your custom implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjuCcJwXxLjJ",
        "outputId": "25ac950e-5ea1-4679-9851-7fb432367f1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocabulary_with_dimension=  {'and': 0, 'document': 1, 'first': 2, 'is': 3, 'one': 4, 'second': 5, 'the': 6, 'third': 7, 'this': 8}\n"
          ]
        }
      ],
      "source": [
        "# Write your code here.\n",
        "# Make sure its well documented and readble with appropriate comments.\n",
        "# Compare your results with the above sklearn tfidf vectorizer\n",
        "# You are not supposed to use any other library apart from the ones given below\n",
        "\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "import operator\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np\n",
        "\n",
        "def fit(corpus):\n",
        "  '''\n",
        "  This function generates a dictionary set/Vocabulary and\n",
        "  returns :\n",
        "  vocabulary = list of unique words in corpus\n",
        "  vocabulary_with_dimension = {word : dimension no}\n",
        "  '''\n",
        "  unique_words = []\n",
        "  dimension = []\n",
        "  i=0\n",
        "  for sentence in corpus:\n",
        "    for word in sentence.split():\n",
        "      if word not in unique_words:\n",
        "        unique_words.append(word)\n",
        "        dimension.append(i)\n",
        "        i+=1\n",
        "  vocabulory = sorted(unique_words)\n",
        "  vocabulary_with_dimension = dict(zip(vocabulory,dimension))\n",
        "  return vocabulary_with_dimension, vocabulory\n",
        "\n",
        "vocabulary_with_dimension, vocabulory = fit(corpus)\n",
        "print(\"vocabulary_with_dimension= \",vocabulary_with_dimension )    \n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSfPq6nLdGaq",
        "outputId": "78f606f8-4b28-426a-dc7d-8b49a4cb0618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.916290731874155, 1.2231435513142097, 1.5108256237659907, 1.0, 1.916290731874155, 1.916290731874155, 1.0, 1.916290731874155, 1.0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def calcualte_idf(vocabulory):\n",
        "  '''\n",
        "  This method calculates the IDF value for each word in dictionary \n",
        "  set/Vocabulary so generated in method \"fit\"\n",
        "  returns: list of IDF values corresponding to each word in Vocabulary\n",
        "  '''\n",
        "  N = len(corpus)\n",
        "  idf_value = []\n",
        "  for word in vocabulory:\n",
        "    total_count = 0\n",
        "    for sentence in corpus:\n",
        "      if word in sentence.split():\n",
        "        total_count+=1\n",
        "\n",
        "    # calculating idf values\n",
        "    idf_val = 1+ np.log(((1 + N) / (1 + total_count)))\n",
        "    idf_value.append(idf_val)\n",
        "  return idf_value\n",
        "\n",
        "idf_value = calcualte_idf(vocabulory)\n",
        "print(idf_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c6oxrgQeIAP",
        "outputId": "e9deec22-af7a-4c85-9b3f-7dbfee005361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 1)\t0.4697913855799205\n",
            "  (0, 2)\t0.580285823684436\n",
            "  (0, 3)\t0.3840852409148149\n",
            "  (0, 6)\t0.3840852409148149\n",
            "  (0, 8)\t0.3840852409148149\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ]
        }
      ],
      "source": [
        "def transform(corpus,idf_value):\n",
        "  '''\n",
        "  This method calculates the TF * IDF value for each word in dictionary \n",
        "  set/Vocabulary so generated in method \"fit\" along with the words\n",
        "  position in matrix\n",
        "  returns: returns: Normalized Sparse matrix : normalized_sparse_matrix\n",
        "\n",
        "  '''\n",
        "  row_no = 0\n",
        "  final_TF_IDF_list = []\n",
        "\n",
        "  #  For each document in corpus\n",
        "  for sentence in corpus:\n",
        "    len_sentence = len(sentence.split())\n",
        "\n",
        "    # for each unique word in the dicitionary set/vocabulory\n",
        "    for word in vocabulary_with_dimension:\n",
        "      count_word_in_sentence= (sentence.split()).count(word)\n",
        "\n",
        "      #  Calculating TF value\n",
        "      tf_val = count_word_in_sentence / len_sentence\n",
        "\n",
        "      # vocabulary_with_dimension[word] : gives the dimension number \n",
        "      # corresponding to word\n",
        "      # hence idf_value[vocabulary_with_dimension[word]] will get us the idf \n",
        "      # value corresponding to 'word'\n",
        "\n",
        "      tf_idf_calc = tf_val * idf_value[vocabulary_with_dimension[word]]\n",
        "\n",
        "      # calculating position (row_no,col_no) \n",
        "      position = (row_no,vocabulary_with_dimension[word])\n",
        "\n",
        "      # Appending list conatining position of word and its corresponding value\n",
        "      final_TF_IDF_list.append([position,tf_idf_calc])\n",
        "\n",
        "    row_no += 1\n",
        "  \n",
        "  # Creation of sparse matrix\n",
        "  sparse_matrix = []\n",
        "\n",
        "  for list_element in enumerate(final_TF_IDF_list):\n",
        "    # print(list_element)\n",
        "    if list_element[1][1] != 0.0:\n",
        "      # del sparse_matrix[list_element[0]]\n",
        "      sparse_matrix.append(list_element[1])\n",
        "\n",
        "  # getting paramaters of csr_matrix to get the sparse matrix\n",
        "  row = []\n",
        "  col = []\n",
        "  val = []\n",
        "  for i in sparse_matrix:\n",
        "    row.append(i[0][0])\n",
        "    col.append(i[0][1])\n",
        "    val.append(i[1])\n",
        "  \n",
        "  # Creation of sparse matrix using csr_matrix\n",
        "  sparse_matrix = csr_matrix((val,(row,col)),shape=(len(corpus),len(vocabulary_with_dimension)))\n",
        "\n",
        "  # Normalizing Sparse matrix\n",
        "  normalized_sparse_matrix = normalize(sparse_matrix)\n",
        "\n",
        "  return normalized_sparse_matrix\n",
        "\n",
        "\n",
        "sparse_matrix = transform(corpus,idf_value)\n",
        "print(sparse_matrix[0])\n",
        "print(type(sparse_matrix))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHxPLlwNxLjL",
        "outputId": "6b50b6e6-9355-4a5a-a0a3-f416d2bfa8c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of documents in corpus =  746\n"
          ]
        }
      ],
      "source": [
        "# Below is the code to load the cleaned_strings pickle file provided\n",
        "# Here corpus is of list type\n",
        "\n",
        "import pickle\n",
        "with open('cleaned_strings', 'rb') as f:\n",
        "    corpus = pickle.load(f)\n",
        "    \n",
        "# printing the length of the corpus loaded\n",
        "print(\"Number of documents in corpus = \",len(corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ZULfoOIdxLjQ"
      },
      "outputs": [],
      "source": [
        "def fit(corpus):\n",
        "  '''\n",
        "  This function generates a dictionary set/Vocabulary for BOW and returns\n",
        "  vocabulary = list of unique words in corpus\n",
        "  vocabulary_with_dimension = {word : dimension no}\n",
        "  '''\n",
        "  unique_words = []\n",
        "  dimension = []\n",
        "  i=0\n",
        "  for sentence in corpus:\n",
        "    for word in sentence.split():\n",
        "      if word not in unique_words:\n",
        "        unique_words.append(word)\n",
        "        dimension.append(i)\n",
        "        i+=1\n",
        "  vocabulory = sorted(unique_words)\n",
        "  vocabulary_with_dimension = dict(zip(vocabulory,dimension))\n",
        "  return vocabulary_with_dimension, vocabulory\n",
        "\n",
        "vocabulary_with_dimension, vocabulory = fit(corpus)\n",
        "# print(\"vocabulary = \",vocabulary_with_dimension )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvY32HjOdn0v",
        "outputId": "cf477219-81e8-440e-9753-e5ebcc54d486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'aailiyah': 6.922918004572872, 'abandoned': 6.922918004572872, 'abroad': 6.922918004572872, 'abstruse': 6.922918004572872, 'academy': 6.922918004572872, 'accents': 6.922918004572872, 'accessible': 6.922918004572872, 'acclaimed': 6.922918004572872, 'accolades': 6.922918004572872, 'accurate': 6.922918004572872, 'accurately': 6.922918004572872, 'achille': 6.922918004572872, 'ackerman': 6.922918004572872, 'actions': 6.922918004572872, 'adams': 6.922918004572872, 'add': 6.922918004572872, 'added': 6.922918004572872, 'admins': 6.922918004572872, 'admiration': 6.922918004572872, 'admitted': 6.922918004572872, 'adrift': 6.922918004572872, 'adventure': 6.922918004572872, 'aesthetically': 6.922918004572872, 'affected': 6.922918004572872, 'affleck': 6.922918004572872, 'afternoon': 6.922918004572872, 'aged': 6.922918004572872, 'ages': 6.922918004572872, 'agree': 6.922918004572872, 'agreed': 6.922918004572872, 'aimless': 6.922918004572872, 'aired': 6.922918004572872, 'akasha': 6.922918004572872, 'akin': 6.922918004572872, 'alert': 6.922918004572872, 'alike': 6.922918004572872, 'allison': 6.922918004572872, 'allow': 6.922918004572872, 'allowing': 6.922918004572872, 'alongside': 6.922918004572872, 'amateurish': 6.922918004572872, 'amaze': 6.922918004572872, 'amazed': 6.922918004572872, 'amazingly': 6.922918004572872, 'amusing': 6.922918004572872, 'amust': 6.922918004572872, 'anatomist': 6.922918004572872, 'angel': 6.922918004572872, 'angela': 6.922918004572872, 'angelina': 6.922918004572872}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def calcualte_idf(vocabulory):\n",
        "  '''\n",
        "  This method calculates the IDF value for each word in dictionary \n",
        "  set/Vocabulary so generated in method \"fit\" and takes top 50 IDF values\n",
        "  returns: dictionary of top 50 IDF values corresponding to each word in Vocabulary\n",
        "  with words as keys and IDF score as values\n",
        "  '''\n",
        "  N = len(corpus)\n",
        "  idf_value = []\n",
        "  for word in vocabulory:\n",
        "    total_count = 0\n",
        "    for sentence in corpus:\n",
        "      if word in sentence.split():\n",
        "        total_count+=1\n",
        "\n",
        "    # calculating idf values\n",
        "    idf_val = 1+ np.log(((1 + N) / (1 + total_count)))\n",
        "    idf_value.append(idf_val)\n",
        "\n",
        "    # Creating dictionary of word (as key) with its corresponding IDF score (as value)\n",
        "    word_with_idf = dict(zip(vocabulory,idf_value))\n",
        "\n",
        "    # Get top 50 words with maxm Idf scores : dictionary format\n",
        "    top_50_IDF_vocabulory_dict = dict(sorted(word_with_idf.items(),key= lambda x : x[1],reverse=True)[:50])\n",
        "\n",
        "  return top_50_IDF_vocabulory_dict\n",
        "\n",
        "top_50_IDF_vocabulory_dict = calcualte_idf(vocabulory)\n",
        "print(top_50_IDF_vocabulory_dict)\n",
        "\n",
        "\n",
        "# Get top 50 words with maxm Idf scores : list of words\n",
        "top_50_IDF_vocabulory = list(top_50_IDF_vocabulory_dict.keys())\n",
        "\n",
        "# Top 50 IDF Values\n",
        "top_50_IDF_values = list(top_50_IDF_vocabulory_dict.values())\n",
        "\n",
        "# Override value of  \"vocabulary_with_dimension\" with top 50 words and its dimensions\n",
        "\n",
        "dimension = [i for i in range(50)]\n",
        "\n",
        "vocabulary_with_dimension = dict(zip(top_50_IDF_vocabulory,dimension))\n",
        "# print(vocabulary_with_dimension)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVDEO0V3gKD5",
        "outputId": "56f568b7-6474-46e3-edbe-0aaba54e7d55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 30)\t1.0\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]]\n",
            "(746, 50)\n"
          ]
        }
      ],
      "source": [
        "def transform(corpus,idf_value):\n",
        "  '''\n",
        "  This method calculates the TF * IDF value for each word in dictionary \n",
        "  set/Vocabulary so generated in method \"fit\" along with the words\n",
        "  position in matrix\n",
        "  returns: Normalized Sparse matrix : normalized_sparse_matrix\n",
        "\n",
        "  '''\n",
        "  row_no = 0\n",
        "  final_TF_IDF_list = []\n",
        "\n",
        "  #  For each document in corpus\n",
        "  for sentence in corpus:\n",
        "    len_sentence = len(sentence.split())\n",
        "    # for each unique word in the dicitionary set/vocabulory\n",
        "    for word in vocabulary_with_dimension:\n",
        "      count_word_in_sentence= (sentence.split()).count(word)\n",
        "\n",
        "      #  Calculating TF value\n",
        "      tf_val = count_word_in_sentence / len_sentence\n",
        "\n",
        "      # vocabulary_with_dimension[word] : gives the dimension number corresponding to word\n",
        "      # hence idf_value[vocabulary_with_dimension[word] will get us the idf value corresponding to 'word'\n",
        "      tf_idf_calc = tf_val * idf_value[vocabulary_with_dimension[word]]\n",
        "\n",
        "      # calculating position (row_no,col_no) \n",
        "      position = (row_no,vocabulary_with_dimension[word])\n",
        "\n",
        "      # Appending list conatining position of word and its corresponding value\n",
        "      final_TF_IDF_list.append([position,tf_idf_calc])\n",
        "\n",
        "    row_no += 1\n",
        "\n",
        "  # Creation of sparse matrix\n",
        "  sparse_matrix = []\n",
        "\n",
        "  for list_element in enumerate(final_TF_IDF_list):\n",
        "    # print(list_element)\n",
        "    if list_element[1][1] != 0.0:\n",
        "      # del sparse_matrix[list_element[0]]\n",
        "      sparse_matrix.append(list_element[1])\n",
        "\n",
        "  # getting paramaters of csr_matrix to get the sparse matrix\n",
        "  row = []\n",
        "  col = []\n",
        "  val = []\n",
        "  for i in sparse_matrix:\n",
        "    row.append(i[0][0])\n",
        "    col.append(i[0][1])\n",
        "    val.append(i[1])\n",
        "\n",
        "  # Creation of sparse matrix using csr_matrix\n",
        "  sparse_matrix = csr_matrix((val,(row,col)),shape=(len(corpus),len(vocabulary_with_dimension)))\n",
        "\n",
        "  # Normalizing Sparse matrix\n",
        "  normalized_sparse_matrix = normalize(sparse_matrix)\n",
        "  return normalized_sparse_matrix\n",
        "\n",
        "sparse_matrix = transform(corpus,top_50_IDF_values)\n",
        "print(sparse_matrix[0])\n",
        "print(sparse_matrix[0].toarray())\n",
        "print(sparse_matrix.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "1_DJnnR3xLjR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Solution_Assignment_3_TF IDF Vectorizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
